{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":107555,"databundleVersionId":13033998,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Submission with stacking with logistic regression, knn, xgboost and random forest","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nimport os\nimport numpy as np\n\n# --- Define the path to our data ---\nCOMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\nDATA_PATH = os.path.join('../input', COMPETITION_NAME)\n\ntrain_file_path = os.path.join(DATA_PATH, 'train.jsonl')\ntest_file_path = os.path.join(DATA_PATH, 'test.jsonl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:27:46.948116Z","iopub.execute_input":"2025-11-14T18:27:46.948411Z","iopub.status.idle":"2025-11-14T18:27:47.287608Z","shell.execute_reply.started":"2025-11-14T18:27:46.948385Z","shell.execute_reply":"2025-11-14T18:27:47.286791Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = []\n\nprint(f\"Loading data from '{train_file_path}'...\")\ntry:\n    with open(train_file_path, 'r') as f:\n        for line in f:\n            train_data.append(json.loads(line))\n        print(f\"Successfully loaded {len(train_data)} battles.\")\n        \n    # Let's inspect the first battle to see its structure\n    print(\"\\n--- Structure of the first train battle: ---\")\n    if train_data:\n        first_battle = train_data[0]\n        \n        battle_for_display = first_battle.copy()\n        battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', []) [:2] # Show first 2 turns\n        \n        print(json.dumps(battle_for_display, indent=4))\n        if len(first_battle.get('battle_timeline', [])) > 2:\n            print(\"    ...\")\n            print(\"    (battle_timeline has been truncated for display)\")\n\n\nexcept FileNotFoundError:\n    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n    print(\"Please make sure you have added the competition data to this notebook.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:27:50.300931Z","iopub.execute_input":"2025-11-14T18:27:50.301367Z","iopub.status.idle":"2025-11-14T18:27:57.189006Z","shell.execute_reply.started":"2025-11-14T18:27:50.301344Z","shell.execute_reply":"2025-11-14T18:27:57.187887Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = []\n\nprint(f\"Loading data from '{test_file_path}'...\")\ntry:\n    with open(test_file_path, 'r') as f:\n        for line in f:\n            test_data.append(json.loads(line))\n    \n    print(\"\\n--- Structure of the first test battle: ---\")\n    if test_data:\n            first_test_battle = test_data[0]\n            \n            test_battle_for_display = first_test_battle.copy()\n            test_battle_for_display['battle_timeline'] = test_battle_for_display.get('battle_timeline', [])[:2] # Show first 2 turns\n            \n            print(json.dumps(test_battle_for_display, indent=4))\n            if len(first_test_battle.get('battle_timeline', [])) > 3:\n                print(\"    ...\")\n                print(\"    (battle_timeline has been truncated for display)\")\n\n\nexcept FileNotFoundError:\n    print(f\"ERROR: Could not find the training file at '{test_file_path}'.\")\n    print(\"Please make sure you have added the competition data to this notebook.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:28:04.994405Z","iopub.execute_input":"2025-11-14T18:28:04.994745Z","iopub.status.idle":"2025-11-14T18:28:07.852300Z","shell.execute_reply.started":"2025-11-14T18:28:04.994720Z","shell.execute_reply":"2025-11-14T18:28:07.851532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"count_level = 0\nfor battle in train_data:\n    squad = battle.get(\"p1_team_details\")\n    for pokemon in squad:\n        level = pokemon.get(\"level\")\n        if level != 100:\n            count_level += 1\nprint(count_level)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:28:23.798718Z","iopub.execute_input":"2025-11-14T18:28:23.799001Z","iopub.status.idle":"2025-11-14T18:28:23.828985Z","shell.execute_reply.started":"2025-11-14T18:28:23.798978Z","shell.execute_reply":"2025-11-14T18:28:23.828256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"used_pokemon = set()\ncount = 0\nfor battle in train_data:\n    battle_timeline = battle.get('battle_timeline', [])\n    for i in battle_timeline:\n        nome_p1 = i.get(\"p1_pokemon_state\").get(\"name\")\n        nome_p2 = i.get(\"p2_pokemon_state\").get(\"name\")\n        if nome_p1 not in used_pokemon:\n            used_pokemon.add(nome_p1)\n            count += 1\n        if nome_p2 not in used_pokemon:\n            used_pokemon.add(nome_p2)\n            count += 1\nprint(count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:28:26.605761Z","iopub.execute_input":"2025-11-14T18:28:26.606027Z","iopub.status.idle":"2025-11-14T18:28:26.794417Z","shell.execute_reply.started":"2025-11-14T18:28:26.606000Z","shell.execute_reply":"2025-11-14T18:28:26.793451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pokedex = {}\n\nfor battle in train_data:\n    squad = battle.get(\"p1_team_details\")\n    for pokemon in squad:\n        nome = pokemon.get(\"name\")\n        if nome not in pokedex:\n            pokedex[nome] = pokemon\n    pokemon_p2 = battle.get(\"p2_lead_details\").get(\"name\")\n    if pokemon_p2 not in pokedex:\n        pokedex[pokemon_p2] = battle.get(\"p2_lead_details\")\n\nprint(len(pokedex))\n#print(json.dumps(pokedex, indent=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:28:29.989198Z","iopub.execute_input":"2025-11-14T18:28:29.989531Z","iopub.status.idle":"2025-11-14T18:28:30.025689Z","shell.execute_reply.started":"2025-11-14T18:28:29.989485Z","shell.execute_reply":"2025-11-14T18:28:30.024837Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Feature engineering** \nWe create a function **create_simple_features** that takes as input a list of dictionaries (jsonl files) and returns a dataframe containing all the features we created.","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport numpy as np\n\ndef create_simple_features(data: list[dict]) -> pd.DataFrame:\n\n    \n    feature_list = []\n    for battle in tqdm(data, desc=\"Extracting features\"):\n        features = {}\n\n        \n        # --- Player 1 Team Features ---\n        p1_team = battle.get('p1_team_details', [])\n        if p1_team:\n            features['p1_mean_hp'] = np.mean([p.get('base_hp', 0) for p in p1_team])\n            features['p1_mean_spe'] = np.mean([p.get('base_spe', 0) for p in p1_team])\n            features['p1_mean_atk'] = np.mean([p.get('base_atk', 0) for p in p1_team])\n            features['p1_mean_def'] = np.mean([p.get('base_def', 0) for p in p1_team])\n            features['p1_mean_spa'] = np.mean([p.get('base_spa', 0) for p in p1_team])\n            features['p1_mean_spd'] = np.mean([p.get('base_spd', 0) for p in p1_team])\n\n        \n        # --- Player 2 Team Features ---\n        \n        battle_timeline = battle.get('battle_timeline', [])\n        p2_team = {}\n        for i in battle_timeline:\n            name_p2 = i.get(\"p2_pokemon_state\", {}).get(\"name\")\n            if name_p2:\n                p2_team[name_p2] = pokedex.get(name_p2, {})\n        features['p2_mean_hp'] = np.mean([p2_team[p].get('base_hp', 0) for p in p2_team])\n        features['p2_mean_spe'] = np.mean([p2_team[p].get('base_spe', 0) for p in p2_team])\n        features['p2_mean_atk'] = np.mean([p2_team[p].get('base_atk', 0) for p in p2_team])\n        features['p2_mean_def'] = np.mean([p2_team[p].get('base_def', 0) for p in p2_team])\n        features['p2_mean_spa'] = np.mean([p2_team[p].get('base_spa', 0) for p in p2_team])\n        features['p2_mean_spd'] = np.mean([p2_team[p].get('base_spd', 0) for p in p2_team])\n\n        \n        # --- Players' Status pokemon ---\n        \n        status_p1 = (sum(i.get(\"p1_pokemon_state\", {}).get(\"status\") != \"nostatus\" for i in battle_timeline))/len(battle_timeline)\n        status_p2 = (sum(i.get(\"p2_pokemon_state\", {}).get(\"status\") != \"nostatus\" for i in battle_timeline))/len(battle_timeline)\n\n        features['p1_status'] =  round(status_p1,3)\n        features['p2_status'] =  round(status_p2,3)\n        features[\"diff_status\"] = features['p1_status'] - features['p2_status']\n\n\n        # --- Players' Boosts ---\n                \n        boosts_p1 = sum(sum(i.get(\"p1_pokemon_state\", {}).get(\"boosts\", {}).values()) for i in battle_timeline)\n        boosts_p2 = sum(sum(i.get(\"p2_pokemon_state\", {}).get(\"boosts\", {}).values()) for i in battle_timeline)\n        \n        features[\"boosts_p1\"] = boosts_p1\n        features[\"boosts_p2\"] = boosts_p2\n        features[\"diff_boost\"] = boosts_p1 - boosts_p2\n        \n        \n        # --- Players' move \"null\" ---\n        \n        null_1 = sum(not i.get(\"p1_move_details\") for i in battle_timeline)\n        null_2 = sum(not i.get(\"p2_move_details\") for i in battle_timeline)\n        \n        features['null_p1'] = null_1\n        features['null_p2'] = null_2\n\n        \n        # --- Players' accuracy ---\n        \n        acc_1 = 0\n        n_acc1 = 0\n        acc_2 = 0\n        n_acc2 = 0\n        \n        for i in battle_timeline:\n            \n            if i.get('p1_move_details'):\n                acc_1 += float(i.get('p1_move_details').get('accuracy'))\n                n_acc1 += 1\n            if i.get('p2_move_details'):\n                acc_2 += float(i.get('p2_move_details').get('accuracy'))\n                n_acc2 += 1\n        \n        if n_acc1 != 0:\n            features['avg_acc_p1'] = acc_1/n_acc1\n        else:\n            features['avg_acc_p1'] = 0\n        \n        if n_acc2 != 0:\n            features['avg_acc_p2'] = acc_2/n_acc2\n        else:\n            features['avg_acc_p2'] = 0\n                \n        \n        features[\"diff_avg_acc\"] = features['avg_acc_p1'] - features['avg_acc_p2']\n\n        \n        # --- Numbers of time in which each player attacks ---\n\n        diz_p1 = {}\n        count_p2 = 0\n        for i in battle_timeline:\n            nome = i.get('p1_pokemon_state').get('name')\n            hp = i.get('p1_pokemon_state').get('hp_pct')\n            if nome not in diz_p1:\n                if int(hp) != 1:\n                    diz_p1[nome] = hp\n                    count_p2 += 1\n                else:\n                    diz_p1[nome] = hp\n            else:\n                if diz_p1[nome] > hp:\n                    diz_p1[nome] = hp\n                    count_p2 += 1\n                else:\n                    diz_p1[nome] = hp\n        diz_p2 = {}\n        count_p1 = 0\n        for i in battle_timeline:\n            nome = i.get('p2_pokemon_state').get('name')\n            hp = i.get('p2_pokemon_state').get('hp_pct')\n            if nome not in diz_p2:\n                if int(hp) != 1:\n                    diz_p2[nome] = hp\n                    count_p1 += 1\n                else:\n                    diz_p2[nome] = hp\n            else:\n                if diz_p2[nome] > hp:\n                    diz_p2[nome] = hp\n                    count_p1 += 1\n                else:\n                    diz_p2[nome] = hp\n\n        features['n_atk_p1'] = count_p1\n        features['n_atk_p2'] = count_p2\n\n        \n        # --- Difference of damage inflicted ---\n\n        diz_1 = {}\n        def_p1 = 0 # sum of all hp (in percentage) lost by pokemon of player 1 \n        diz_2 = {}\n        atk_p1 = 0 # sum of all hp (in percentage) lost by pokemon of player 2\n        \n        for i in battle_timeline:\n            # sum of p1 defense\n            diff_p1 = 0\n            nome_1 = i.get(\"p1_pokemon_state\").get(\"name\")\n            hp_1 = i.get(\"p1_pokemon_state\").get(\"hp_pct\")\n            if nome_1 not in diz_1:\n                if int(hp_1) != 1:\n                    diff_p1 = 1 - hp_1\n                    diz_1[nome_1] = hp_1\n                else:\n                    diz_1[nome_1] = hp_1\n            else:\n                diff_p1 = diz_1[nome_1] - hp_1\n                diz_1[nome_1] = hp_1\n            def_p1 += diff_p1 \n            \n        for i in battle_timeline:\n            # sum of p1 attack\n            diff_p2 = 0\n            nome_2 = i.get(\"p2_pokemon_state\").get(\"name\")\n            hp_2 = i.get(\"p2_pokemon_state\").get(\"hp_pct\")   \n            if nome_2 not in diz_2:\n                if int(hp_2) != 1:\n                    diff_p2 = 1 - hp_2\n                    diz_2[nome_2] = hp_2\n                else:\n                    diz_2[nome_2] = hp_2\n            else:\n                diff_p2 = diz_2[nome_2] - hp_2\n                diz_2[nome_2] = hp_2\n            atk_p1 += diff_p2\n        \n        features[\"diff_damage\"] = atk_p1 - def_p1\n\n        \n        # --- Count priority ---\n        \n        priority_1 = sum(i[\"p1_move_details\"][\"priority\"] for i in battle_timeline if i.get(\"p1_move_details\"))\n        priority_2 = sum(i[\"p2_move_details\"][\"priority\"] for i in battle_timeline if i.get(\"p2_move_details\"))\n        \n        features[\"priority_1\"] = priority_1\n        features[\"priority_2\"] = priority_2\n        features[\"diff_priority\"] = priority_1 - priority_2\n\n                \n\n        # --- Players' KO ---\n\n        count_p1 = sum(i.get('p1_pokemon_state', {}).get('status') == 'fnt' for i in battle_timeline)\n        count_p2 = sum(i.get('p2_pokemon_state', {}).get('status') == 'fnt' for i in battle_timeline)\n        \n        features['ko_p1'] = count_p1\n        features['ko_p2'] = count_p2\n        features[\"diff_ko\"] = count_p1 - count_p2\n\n\n        # --- Number of special attacks ---\n        \n        count_p1 = 0\n        sp_atk_1 = 0\n        count_p2 = 0\n        sp_def_1 = 0\n        \n        for i in battle_timeline:\n            if i.get(\"p1_move_details\"):\n                nome_p1 = i.get(\"p1_pokemon_state\").get(\"name\")\n                if i.get('p1_move_details').get('category') == 'SPECIAL':\n                    count_p1 += 1\n                    sp_atk_1 += next(p.get('base_spa', 0) for p in p1_team if p.get(\"name\") == nome_p1)\n            if i.get(\"p2_move_details\"):\n                if i.get('p2_move_details').get('category') == 'SPECIAL':\n                    count_p2 += 1\n        \n        features['n_sp_atk_1'] = count_p1\n        features['n_sp_atk_2'] = count_p2\n        features[\"diff_sp_atk\"] = count_p1 - count_p2\n        \n        if count_p1 != 0:\n            features[\"avg_sp_atk_1\"] = sp_atk_1 / count_p1\n        else:\n            features[\"avg_sp_atk_1\"] = 0\n            \n        \n        # --- Number of times that each player uses blizard / ice beam ---\n        \n        count_move_p1_frz = 0\n        count_move_p2_frz = 0\n\n        count_move_p1_frz = sum(1 for turn in battle_timeline \n                                if turn.get(\"p1_move_details\") \n                                and turn.get(\"p1_move_details\").get(\"name\") in [\"blizzard\", \"icebeam\"])\n            \n        count_move_p2_frz = sum(1 for turn in battle_timeline \n                                if turn.get(\"p2_move_details\") \n                                and turn.get(\"p2_move_details\").get(\"name\") in [\"blizzard\", \"icebeam\"])\n            \n        features[\"move_p1_blz-icb\"] = count_move_p1_frz\n        features[\"move_p2_blz-icb\"] = count_move_p2_frz \n\n      \n        # --- Number of times that each player uses thunderwave ---\n        \n        count_move_p1_spe = 0\n        count_move_p2_spe = 0\n\n        count_move_p1_spe = sum(1 for turn in battle_timeline\n                                if turn.get(\"p1_move_details\") \n                                and turn.get(\"p1_move_details\").get(\"name\") == \"thunderwave\")\n            \n        count_move_p2_spe = sum(1 for turn in battle_timeline\n                                if turn.get(\"p2_move_details\") \n                                and turn.get(\"p2_move_details\").get(\"name\") == \"thunderwave\")\n            \n        features[\"move_p1_tw\"] = count_move_p1_spe\n        features[\"move_p2_tw\"] = count_move_p1_spe\n\n        \n        # --- effects count ---\n\n        effects_p1 = sum(1 for i in battle_timeline if i.get('p1_pokemon_state').get(\"effects\")[0] != 'noeffect')\n        effects_p2 = sum(1 for i in battle_timeline if i.get('p2_pokemon_state').get(\"effects\")[0] != 'noeffect')\n        \n        features['p1_effects'] =  round((effects_p1/len(battle_timeline)),3)\n        features['p2_effects'] =  round((effects_p2/len(battle_timeline)),3)\n        features[\"diff_effetcs\"] = features['p1_effects'] - features['p2_effects']\n\n\n        # --- some interactions ---\n        \n        features[\"p2_status x null_p2\"] = features[\"p2_status\"]*null_2\n        features[\"p1_status x null_p1\"] = features[\"p1_status\"]*null_1\n        \n\n            \n        # ID and the target variable \n        \n        features['battle_id'] = battle.get('battle_id')\n        if 'player_won' in battle:\n            features['player_won'] = int(battle['player_won'])\n            \n        feature_list.append(features)\n        \n    return pd.DataFrame(feature_list).fillna(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:51:20.800334Z","iopub.execute_input":"2025-11-14T18:51:20.800659Z","iopub.status.idle":"2025-11-14T18:51:20.833256Z","shell.execute_reply.started":"2025-11-14T18:51:20.800635Z","shell.execute_reply":"2025-11-14T18:51:20.832231Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We call the function twice, first giving as input the train data and then the test data such that we obtain the two dataframe for training and test. Then we create the final datasets for training (removing ID's & target features) and for the test.","metadata":{}},{"cell_type":"code","source":"# Features' dataframe for training set\n\ntrain_df = create_simple_features(train_data)\n\n# Features' dataframe for training set\n\ntest_df = create_simple_features(test_data)\n\ndisplay(train_df.head(5))\ndisplay(train_df.tail(5))\n\ntrain_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T18:51:27.668078Z","iopub.execute_input":"2025-11-14T18:51:27.668382Z","iopub.status.idle":"2025-11-14T18:51:32.490217Z","shell.execute_reply.started":"2025-11-14T18:51:27.668356Z","shell.execute_reply":"2025-11-14T18:51:32.489423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Defining our features (X) and target (y)\n\nfeatures = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\nX_train = train_df[features]\ny_train = train_df['player_won']\nprint (features)\nX_test = test_df[features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:01:54.581614Z","iopub.execute_input":"2025-11-14T19:01:54.582582Z","iopub.status.idle":"2025-11-14T19:01:54.590429Z","shell.execute_reply.started":"2025-11-14T19:01:54.582553Z","shell.execute_reply":"2025-11-14T19:01:54.589629Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In the folliwing cell we create different subsets for each base model we want to put in the stacking.  \nThe idea is to create as much diversity as possibile between the model allowing them to be trained on the best possible set of features (giving them features that generates less confusion as possible). Then using the stacking ensamble method we hope to gain as mush information as possible from all the models.","metadata":{}},{"cell_type":"code","source":"features_lr = [feature for feature in features if feature not in [\"avg_sp_atk_1\", \"diff_ko\", \n                                                                 \n                                                                 \"avg_acc_p1\", \"avg_acc_p2\",\"diff_sp_atk\", \"diff_status\"\n                                                                  ]]\n\n\nfeatures_knn = [feature for feature in features if feature not in [\"avg_sp_atk_1\", \"diff_ko\", \n                                                                 \"diff_priority\", \"boosts_p1\", \"boosts_p2\",\n                                                                 \"avg_acc_p1\", \"avg_acc_p2\",\"diff_sp_atk\", \"diff_status\",\n                                                                  \"p1_effects\", \"p2_effects\",\"diff_effetcs\",\n                                                                  \"null_p1\",\"ko_p2\",\"move_p1_blz-icb\" , \"move_p2_tw\", \n                                                                  \"p1_mean_spd\", \"move_p2_blz-icb\",\"priority_2\", \n                                                                  \"diff_boost\",\"p2_status x null_p2\", \"p2_mean_spa\", \n                                                                  \"p1_mean_def\",\"p1_mean_spa\", \"ko_p1\", \n                                                                  \"p2_mean_spd\", \"p2_mean_def\",\"p1_mean_atk\",\n                                                                  \"n_sp_atk_1\", \"n_sp_atk_2\",\"move_p1_tw\" ]]\n\n\nfeatures_rf = [feature for feature in features if feature not in [\"avg_sp_atk_1\", \"diff_ko\", \n                                                                 \"diff_priority\", \"boosts_p1\", \"boosts_p2\",\n                                                                 \"avg_acc_p1\", \"avg_acc_p2\",\"diff_sp_atk\", \"diff_status\",\n                                                                  \"p1_effects\", \"p2_effects\",\"diff_effetcs\",]]\n\n\n\nfeatures_xgb = [feature for feature in features if feature not in [\"avg_sp_atk_1\", \"diff_ko\", \n                                                                 \"diff_priority\", \"boosts_p1\", \"boosts_p2\",\n                                                                 \"avg_acc_p1\", \"avg_acc_p2\",\"diff_sp_atk\", \"diff_status\",\n                                                                  \"p1_effects\", \"p2_effects\",\"diff_effetcs\",]]\n\nprint(len(features_lr), len(features_knn), len(features_rf), len(features_xgb))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:05:22.937846Z","iopub.execute_input":"2025-11-14T19:05:22.938226Z","iopub.status.idle":"2025-11-14T19:05:22.946195Z","shell.execute_reply.started":"2025-11-14T19:05:22.938207Z","shell.execute_reply":"2025-11-14T19:05:22.945326Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Scaling**  \nDue to the fact that having features on different scales can create problems and confusion in some models (e.g. knn) we rescale all the variables to mean = 0 and standard deviation = 1.","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)\n\n\nX_test_scaled_df = pd.DataFrame(X_test_scaled, columns= features)\nX_train_scaled_df = pd.DataFrame(X_train_scaled, columns= features )\nX_train_scaled_df.head()\nX_train_scaled_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:05:26.372531Z","iopub.execute_input":"2025-11-14T19:05:26.372794Z","iopub.status.idle":"2025-11-14T19:05:26.518608Z","shell.execute_reply.started":"2025-11-14T19:05:26.372777Z","shell.execute_reply":"2025-11-14T19:05:26.517713Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We do the same standardization to every specific model's training and test sets. ","metadata":{}},{"cell_type":"code","source":"X_train_lr = train_df[features_lr]\nX_test_lr = test_df[features_lr]\nscaler = StandardScaler()\nX_train_lr_scaled = scaler.fit_transform(X_train_lr)\nX_test_lr_scaled = scaler.fit_transform(X_test_lr)\n\nX_train_knn = train_df[features_knn]\nX_test_knn = test_df[features_knn]\nscaler = StandardScaler()\nX_train_knn_scaled = scaler.fit_transform(X_train_knn)\nX_test_knn_scaled = scaler.fit_transform(X_test_knn)\n\nX_train_xgb = train_df[features_xgb]\nX_test_xgb = test_df[features_xgb]\nscaler = StandardScaler()\nX_train_xgb_scaled = scaler.fit_transform(X_train_xgb)\nX_test_xgb_scaled = scaler.fit_transform(X_test_xgb)\n\nX_train_rf = train_df[features_rf]\nX_test_rf = test_df[features_rf]\nscaler = StandardScaler()\nX_train_rf_scaled = scaler.fit_transform(X_train_rf)\nX_test_rf_scaled = scaler.fit_transform(X_test_rf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:05:30.112055Z","iopub.execute_input":"2025-11-14T19:05:30.112407Z","iopub.status.idle":"2025-11-14T19:05:30.196633Z","shell.execute_reply.started":"2025-11-14T19:05:30.112382Z","shell.execute_reply":"2025-11-14T19:05:30.195794Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Building the model**","metadata":{}},{"cell_type":"markdown","source":"In this section, before coding the final model we compute every single model and set their hyperparameters in order to get the best possible performance:  \nwe implemented:\n- Grid search for logistic regression\n- elbow plot for knn","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\n\nmodel = LogisticRegression(random_state=42, max_iter=1000)\n\n\nparam_grid = {\n    'C': [0.1, 0.5, 1, 1.5, 2],\n    'penalty': ['l1', 'l2'],\n    'solver': ['liblinear', 'lbfgs']\n}\n\n\n\ngrid_logreg = GridSearchCV(\n    estimator=model,\n    param_grid=param_grid,\n    scoring=['roc_auc', 'accuracy'],\n    n_jobs=4,        \n    cv=5,            \n    refit='accuracy',      #  the metric by which we want to take the best estimator\n    return_train_score=True\n)\n\n\ngrid_logreg.fit(X_train_lr_scaled, y_train)\n\ncv_results_df = pd.DataFrame(grid_logreg.cv_results_)\n\npredictions_lr = grid_logreg.best_estimator_.predict(X_test_lr_scaled)\n\nprint(\"Predicted labels:\", predictions_lr[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:05:34.132885Z","iopub.execute_input":"2025-11-14T19:05:34.133259Z","iopub.status.idle":"2025-11-14T19:05:38.715807Z","shell.execute_reply.started":"2025-11-14T19:05:34.133231Z","shell.execute_reply":"2025-11-14T19:05:38.714926Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Displayining of the results obtained:\n- value of accuracy of the model\n","metadata":{}},{"cell_type":"code","source":"cv_df = pd.DataFrame(grid_logreg.cv_results_)\n\nbest_idx = grid_logreg.best_index_\n\nmean_acc = cv_df.loc[best_idx, 'mean_test_accuracy']\n\nprint(\"\\naccuracy\",mean_acc) \n\nbest_log_reg = grid_logreg.best_estimator_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:05:46.664100Z","iopub.execute_input":"2025-11-14T19:05:46.664407Z","iopub.status.idle":"2025-11-14T19:05:46.672211Z","shell.execute_reply.started":"2025-11-14T19:05:46.664387Z","shell.execute_reply":"2025-11-14T19:05:46.671374Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**KNN**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nks = range(1, 30)\n\nscores = [\n    cross_val_score(KNeighborsClassifier(n_neighbors=k), X_train_knn_scaled, y_train, cv=5).mean()\n    for k in ks\n]\n\nplt.plot(ks, scores, marker='o')\nplt.xlabel('k (number of neighbors)')\nplt.ylabel('Cross-Validation Accuracy')\nplt.title('Choosing the Optimal k in KNN')\nplt.grid(True)\nplt.show()\n\n# elbow at 24","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:05:49.165889Z","iopub.execute_input":"2025-11-14T19:05:49.166183Z","iopub.status.idle":"2025-11-14T19:07:08.402240Z","shell.execute_reply.started":"2025-11-14T19:05:49.166161Z","shell.execute_reply":"2025-11-14T19:07:08.401356Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Computing accuracy of KNN on training set with cross-validation","metadata":{}},{"cell_type":"code","source":"acc_knn = cross_val_score(KNeighborsClassifier(n_neighbors = 24), X_train_scaled, y_train, cv = 5).mean()\nprint(acc_knn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:07:13.613854Z","iopub.execute_input":"2025-11-14T19:07:13.614158Z","iopub.status.idle":"2025-11-14T19:07:14.357802Z","shell.execute_reply.started":"2025-11-14T19:07:13.614135Z","shell.execute_reply":"2025-11-14T19:07:14.356897Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**XGBoost**","metadata":{}},{"cell_type":"code","source":"pip install xgboost -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\n\nxgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nacc_xgb = cross_val_score(xgb_clf, X_train_xgb_scaled, y_train, cv =5).mean()\n\nprint(acc_xgb)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:07:18.563386Z","iopub.execute_input":"2025-11-14T19:07:18.563730Z","iopub.status.idle":"2025-11-14T19:07:19.784738Z","shell.execute_reply.started":"2025-11-14T19:07:18.563706Z","shell.execute_reply":"2025-11-14T19:07:19.782865Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Random Forest**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import  RandomForestClassifier\nrf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\nacc_rf = cross_val_score(rf_clf, X_train_rf_scaled, y_train, cv = 5).mean()\n\nprint(acc_rf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:07:22.630685Z","iopub.execute_input":"2025-11-14T19:07:22.630967Z","iopub.status.idle":"2025-11-14T19:07:32.522456Z","shell.execute_reply.started":"2025-11-14T19:07:22.630948Z","shell.execute_reply":"2025-11-14T19:07:32.521557Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We create pipelines (one for each model) to put into the staking code.  \nEvery pipeline first gives to each model its own set of features (we used **ColumnTransformer** function to do this) and the computes the specified model.  \nThanks to ColumnTransformer and to \"passthrough\" we are able to give directly the features set to each model as it is.","metadata":{}},{"cell_type":"code","source":"log_clf = best_log_reg\nknn_clf = KNeighborsClassifier(n_neighbors = 24)\n\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nct_logreg = ColumnTransformer([('sel', 'passthrough', features_lr)])\nct_knn    = ColumnTransformer([('sel', 'passthrough', features_knn)])\nct_rf     = ColumnTransformer([('sel', 'passthrough', features_rf)])\nct_xgb    = ColumnTransformer([('sel', 'passthrough', features_xgb)])\n\n\npipe_logreg = Pipeline([\n    ('cols', ct_logreg),\n    ('clf', log_clf)\n])\n\npipe_knn = Pipeline([\n    ('cols', ct_knn),\n    ('clf', knn_clf)  \n])\n\npipe_rf = Pipeline([\n    ('cols', ct_rf),\n    ('clf', rf_clf)  \n])\n\npipe_xgb = Pipeline([\n    ('cols', ct_xgb),\n    ('clf', xgb_clf)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:07:35.775967Z","iopub.execute_input":"2025-11-14T19:07:35.776319Z","iopub.status.idle":"2025-11-14T19:07:35.782685Z","shell.execute_reply.started":"2025-11-14T19:07:35.776298Z","shell.execute_reply":"2025-11-14T19:07:35.781815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Ensamble (Stacking)**  \nOur choice for this submission is to use stacking ensamble technique using as models all the ones computed previously:\n- logistic regression\n- knn\n- xgboost\n- random forest\nThe idea is to use a logistic regression with inputs given by the labels predicted by the base models. The particularity is that now every base model is trained with its own set of features in order to try to reach the best performance possible.\nTo obtain the best performance with implemented also a grid search to the meta-learner. During the grid search it computes also a cross-validation, required to control overfitting.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import StackingClassifier\n\nmeta_learner = LogisticRegression(random_state = 42, max_iter = 1000)\nstack_tot = StackingClassifier(\n    estimators=[\n        ('log', pipe_logreg),\n        ('knn', pipe_knn),\n        ('rf', pipe_rf),\n        ('xgb', pipe_xgb),\n    ],\n    final_estimator=meta_learner,\n    stack_method='predict_proba',  \n    passthrough=False,             \n    cv=5                           \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:07:39.606966Z","iopub.execute_input":"2025-11-14T19:07:39.607277Z","iopub.status.idle":"2025-11-14T19:07:39.612683Z","shell.execute_reply.started":"2025-11-14T19:07:39.607255Z","shell.execute_reply":"2025-11-14T19:07:39.611552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"param_grid = {\n    'final_estimator__C': [0.1, 1, 1.5, 2],\n    'final_estimator__penalty': ['l1', 'l2'],\n    'final_estimator__solver': ['liblinear', 'lbfgs']\n}\n\ngrid_tot = GridSearchCV(stack_tot, param_grid, scoring = [\"roc_auc\", \"accuracy\"], refit = \"accuracy\",n_jobs = 4 , cv=5)\ngrid_tot.fit(X_train_scaled_df, y_train)\n\npredictions_stack_tot = grid_tot.best_estimator_.predict(X_test_scaled_df)\n\n\ntot_results_df = pd.DataFrame(grid_tot.cv_results_)\n\nbest_idx = grid_tot.best_index_\n\nacc_stack_tot = tot_results_df.loc[best_idx, 'mean_test_accuracy']\nprint(acc_stack_tot)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T19:07:43.030744Z","iopub.execute_input":"2025-11-14T19:07:43.031089Z","iopub.status.idle":"2025-11-14T19:15:34.547480Z","shell.execute_reply.started":"2025-11-14T19:07:43.031062Z","shell.execute_reply":"2025-11-14T19:15:34.546564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Creating the Submission File**  \nThe competition requires a `.csv` file with two columns: `battle_id` and `player_won`. Let's use our trained model to make predictions on the test set and format them correctly.","metadata":{}},{"cell_type":"code","source":"# Make predictions on the test data\nprint(\"Generating predictions on the test set...\")\n\n\n# Create the submission DataFrame\nsubmission_df = pd.DataFrame({\n    'battle_id': test_df['battle_id'],\n    'player_won': predictions_stack_tot\n})\n\n# Save the DataFrame to a .csv file\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"\\n'submission.csv' file created successfully!\")\ndisplay(submission_df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":107555,"databundleVersionId":13033998,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Submission with voting with logistic regression, knn, random forest and xgboost","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nimport os\nimport numpy as np\n\n# --- Define the path to our data ---\nCOMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\nDATA_PATH = os.path.join('../input', COMPETITION_NAME)\n\ntrain_file_path = os.path.join(DATA_PATH, 'train.jsonl')\ntest_file_path = os.path.join(DATA_PATH, 'test.jsonl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:53:18.651778Z","iopub.execute_input":"2025-11-13T20:53:18.651956Z","iopub.status.idle":"2025-11-13T20:53:19.799215Z","shell.execute_reply.started":"2025-11-13T20:53:18.651936Z","shell.execute_reply":"2025-11-13T20:53:19.798581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = []\n\n# Read the file line by line\nprint(f\"Loading data from '{train_file_path}'...\")\ntry:\n    with open(train_file_path, 'r') as f:\n        for line in f:\n            train_data.append(json.loads(line))\n        print(f\"Successfully loaded {len(train_data)} battles.\")\n        \n    # Let's inspect the first battle to see its structure\n    print(\"\\n--- Structure of the first train battle: ---\")\n    if train_data:\n        first_battle = train_data[7]\n        \n        battle_for_display = first_battle.copy()\n        battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', [])[:2] # Show first 2 turns\n        \n        print(json.dumps(battle_for_display, indent=4))\n        if len(first_battle.get('battle_timeline', [])) > 2:\n            print(\"    ...\")\n            print(\"    (battle_timeline has been truncated for display)\")\n\n\nexcept FileNotFoundError:\n    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n    print(\"Please make sure you have added the competition data to this notebook.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:54:45.752581Z","iopub.execute_input":"2025-11-13T20:54:45.752797Z","iopub.status.idle":"2025-11-13T20:54:51.243641Z","shell.execute_reply.started":"2025-11-13T20:54:45.752783Z","shell.execute_reply":"2025-11-13T20:54:51.243010Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = []\n\nprint(f\"Loading data from '{test_file_path}'...\")\ntry:\n    with open(test_file_path, 'r') as f:\n        for line in f:\n            test_data.append(json.loads(line))\n    \n    print(\"\\n--- Structure of the first test battle: ---\")\n    if test_data:\n            first_test_battle = test_data[0]\n            \n            test_battle_for_display = first_test_battle.copy()\n            test_battle_for_display['battle_timeline'] = test_battle_for_display.get('battle_timeline', [])[:2] # Show first 2 turns\n            \n            print(json.dumps(test_battle_for_display, indent=4))\n            if len(first_test_battle.get('battle_timeline', [])) > 3:\n                print(\"    ...\")\n                print(\"    (battle_timeline has been truncated for display)\")\n\n\nexcept FileNotFoundError:\n    print(f\"ERROR: Could not find the training file at '{test_file_path}'.\")\n    print(\"Please make sure you have added the competition data to this notebook.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:55:29.172588Z","iopub.execute_input":"2025-11-13T20:55:29.172821Z","iopub.status.idle":"2025-11-13T20:55:31.640069Z","shell.execute_reply.started":"2025-11-13T20:55:29.172806Z","shell.execute_reply":"2025-11-13T20:55:31.639412Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"count_level = 0\npokemon_not_level_100 = []\nfor battle in train_data:\n    squad = battle.get(\"p1_team_details\")\n    for pokemon in squad:\n        level = pokemon.get(\"level\")\n        if level != 100:\n            print(pokemon.get(\"name\"), pokemon.get(\"level\"))\n            count_level += 1\n            pokemon_not_level_100.append(pokemon)\n#print(count_level)\n#print(pokemon_not_level_100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:55:43.943199Z","iopub.execute_input":"2025-11-13T20:55:43.943435Z","iopub.status.idle":"2025-11-13T20:55:43.968413Z","shell.execute_reply.started":"2025-11-13T20:55:43.943421Z","shell.execute_reply":"2025-11-13T20:55:43.967742Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"used_pokemon = set()\ncount = 0\nfor battle in train_data:\n    battle_timeline = battle.get('battle_timeline', [])\n    for i in battle_timeline:\n        nome_p1 = i.get(\"p1_pokemon_state\").get(\"name\")\n        nome_p2 = i.get(\"p2_pokemon_state\").get(\"name\")\n        if nome_p1 not in used_pokemon:\n            used_pokemon.add(nome_p1)\n            count += 1\n        if nome_p2 not in used_pokemon:\n            used_pokemon.add(nome_p2)\n            count += 1\nprint(count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:55:47.941409Z","iopub.execute_input":"2025-11-13T20:55:47.941645Z","iopub.status.idle":"2025-11-13T20:55:48.097054Z","shell.execute_reply.started":"2025-11-13T20:55:47.941630Z","shell.execute_reply":"2025-11-13T20:55:48.096472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pokedex = {}\n\nfor battle in train_data:\n    squad = battle.get(\"p1_team_details\")\n    for pokemon in squad:\n        nome = pokemon.get(\"name\")\n        if nome not in pokedex:\n            pokedex[nome] = pokemon\n    pokemon_p2 = battle.get(\"p2_lead_details\").get(\"name\")\n    if pokemon_p2 not in pokedex:\n        pokedex[pokemon_p2] = battle.get(\"p2_lead_details\")\n\nprint(len(pokedex))\n#print(json.dumps(pokedex, indent=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:56:05.222523Z","iopub.execute_input":"2025-11-13T20:56:05.222776Z","iopub.status.idle":"2025-11-13T20:56:05.252318Z","shell.execute_reply.started":"2025-11-13T20:56:05.222758Z","shell.execute_reply":"2025-11-13T20:56:05.251717Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Feature engineering** \nWe create a function **create_simple_features** that takes as input a list of dictionaries (jsonl files) and returns a dataframe containing all the features we created.","metadata":{}},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport numpy as np\n\ndef create_simple_features(data: list[dict]) -> pd.DataFrame:\n    \n    feature_list = []\n    for battle in tqdm(data, desc=\"Extracting features\"):\n        \n        features = {}\n        \n        # --- Player 1 Team Features ---\n        \n        p1_team = battle.get('p1_team_details', [])\n        if p1_team:\n            features['p1_mean_hp'] = np.mean([p.get('base_hp', 0) for p in p1_team])\n            features['p1_mean_spe'] = np.mean([p.get('base_spe', 0) for p in p1_team])\n            features['p1_mean_atk'] = np.mean([p.get('base_atk', 0) for p in p1_team])\n            features['p1_mean_def'] = np.mean([p.get('base_def', 0) for p in p1_team])\n            features['p1_mean_spa'] = np.mean([p.get('base_spa', 0) for p in p1_team])\n            features['p1_mean_spd'] = np.mean([p.get('base_spd', 0) for p in p1_team])\n\n        \n        # --- Player 2 Partial Team Features ---\n\n        battle_timeline = battle.get('battle_timeline', [])\n        p2_team = {}\n        for i in battle_timeline:\n            name_p2 = i.get(\"p2_pokemon_state\", {}).get(\"name\")\n            if name_p2:\n                p2_team[name_p2] = pokedex.get(name_p2, {})\n        features['p2_mean_hp'] = np.mean([p2_team[p].get('base_hp', 0) for p in p2_team])\n        features['p2_mean_spe'] = np.mean([p2_team[p].get('base_spe', 0) for p in p2_team])\n        features['p2_mean_atk'] = np.mean([p2_team[p].get('base_atk', 0) for p in p2_team])\n        features['p2_mean_def'] = np.mean([p2_team[p].get('base_def', 0) for p in p2_team])\n        features['p2_mean_spa'] = np.mean([p2_team[p].get('base_spa', 0) for p in p2_team])\n        features['p2_mean_spd'] = np.mean([p2_team[p].get('base_spd', 0) for p in p2_team])\n\n        \n        # --- Players' Status pokemon ---\n        \n        status_p1 = (sum(i.get(\"p1_pokemon_state\", {}).get(\"status\") != \"nostatus\" for i in battle_timeline))/len(battle_timeline)\n        status_p2 = (sum(i.get(\"p2_pokemon_state\", {}).get(\"status\") != \"nostatus\" for i in battle_timeline))/len(battle_timeline)\n\n        features['p1_status'] =  round(status_p1,3)\n        features['p2_status'] =  round(status_p2,3)\n\n       \n        # --- Difference of players' Boosts ---\n                \n        boosts_p1 = sum(sum(i.get(\"p1_pokemon_state\", {}).get(\"boosts\", {}).values()) for i in battle_timeline)\n        boosts_p2 = sum(sum(i.get(\"p2_pokemon_state\", {}).get(\"boosts\", {}).values()) for i in battle_timeline)\n        \n        features[\"diff_boost\"] = boosts_p1 - boosts_p2\n\n        \n        # --- Players' move \"null\" ---\n        \n        null_1 = sum(not i.get(\"p1_move_details\") for i in battle_timeline)\n        null_2 = sum(not i.get(\"p2_move_details\") for i in battle_timeline)\n        \n        features['null_p1'] = null_1\n        features['null_p2'] = null_2\n\n        \n        # --- Difference of players' accuracy (on average) ---\n        \n        acc_1_list = [float(i[\"p1_move_details\"][\"accuracy\"]) for i in battle_timeline if i.get(\"p1_move_details\")]\n        acc_2_list = [float(i[\"p2_move_details\"][\"accuracy\"]) for i in battle_timeline if i.get(\"p2_move_details\")]\n\n        avg_acc1 = sum(acc_1_list) / len(acc_1_list) if acc_1_list else 0\n        avg_acc2 = sum(acc_2_list) / len(acc_2_list) if acc_2_list else 0\n\n        features[\"diff_avg_acc\"] = avg_acc1 - avg_acc2\n\n        \n        # --- Number of times that each player attacks ---\n\n        diz_p1 = {}\n        count_p2 = 0\n        \n        for i in battle_timeline:\n            nome = i.get('p1_pokemon_state').get('name')\n            hp = i.get('p1_pokemon_state').get('hp_pct')\n            if nome not in diz_p1:\n                if int(hp) != 1:\n                    diz_p1[nome] = hp\n                    count_p2 += 1   # if the pokemon is hit on the 1st turn it appears\n                else:\n                    diz_p1[nome] = hp\n            else:\n                if diz_p1[nome] > hp:\n                    diz_p1[nome] = hp\n                    count_p2 += 1\n                else:\n                    diz_p1[nome] = hp\n        \n        diz_p2 = {}\n        count_p1 = 0\n        \n        for i in battle_timeline:\n            nome = i.get('p2_pokemon_state').get('name')\n            hp = i.get('p2_pokemon_state').get('hp_pct')\n            if nome not in diz_p2:\n                if int(hp) != 1:\n                    diz_p2[nome] = hp\n                    count_p1 += 1\n                else:\n                    diz_p2[nome] = hp\n            else:\n                if diz_p2[nome] > hp:\n                    diz_p2[nome] = hp\n                    count_p1 += 1\n                else:\n                    diz_p2[nome] = hp\n\n        features['n_atk_p1'] = count_p1\n        features['n_atk_p2'] = count_p2\n\n        \n        # --- Difference of damage inflicted ---\n\n        diz_1 = {}\n        def_p1 = 0 # sum of all hp (in percentage) lost by pokemon of player 1 \n        diz_2 = {}\n        atk_p1 = 0 # sum of all hp (in percentage) lost by pokemon of player 2\n        \n        for i in battle_timeline:\n            # sum of p1 defense\n            diff_p1 = 0\n            nome_1 = i.get(\"p1_pokemon_state\").get(\"name\")\n            hp_1 = i.get(\"p1_pokemon_state\").get(\"hp_pct\")\n            if nome_1 not in diz_1:\n                if int(hp_1) != 1:\n                    diff_p1 = 1 - hp_1\n                    diz_1[nome_1] = hp_1\n                else:\n                    diz_1[nome_1] = hp_1\n            else:\n                diff_p1 = diz_1[nome_1] - hp_1\n                diz_1[nome_1] = hp_1\n            def_p1 += diff_p1 \n            \n        for i in battle_timeline:\n            # sum of p1 attack\n            diff_p2 = 0\n            nome_2 = i.get(\"p2_pokemon_state\").get(\"name\")\n            hp_2 = i.get(\"p2_pokemon_state\").get(\"hp_pct\")   \n            if nome_2 not in diz_2:\n                if int(hp_2) != 1:\n                    diff_p2 = 1 - hp_2\n                    diz_2[nome_2] = hp_2\n                else:\n                    diz_2[nome_2] = hp_2\n            else:\n                diff_p2 = diz_2[nome_2] - hp_2\n                diz_2[nome_2] = hp_2\n            atk_p1 += diff_p2\n        \n        features[\"diff_damage\"] = atk_p1 - def_p1\n        \n        \n        # --- Count priority ---\n        \n        priority_1 = sum(i[\"p1_move_details\"][\"priority\"] for i in battle_timeline if i.get(\"p1_move_details\"))\n        priority_2 = sum(i[\"p2_move_details\"][\"priority\"] for i in battle_timeline if i.get(\"p2_move_details\"))\n        \n        features[\"priority_1\"] = priority_1\n        features[\"priority_2\"] = priority_2\n\n        \n        # --- Players' KO ---\n\n        count_p1 = sum(i.get('p1_pokemon_state', {}).get('status') == 'fnt' for i in battle_timeline)\n        count_p2 = sum(i.get('p2_pokemon_state', {}).get('status') == 'fnt' for i in battle_timeline)\n        \n        features['ko_p1'] = count_p1\n        features['ko_p2'] = count_p2\n\n\n        # --- Number of special attacks ---\n        \n        count_p1 = 0\n        sp_atk_1 = 0\n        count_p2 = 0\n        sp_def_1 = 0\n        \n        for i in battle_timeline:\n            if i.get(\"p1_move_details\"):\n                nome_p1 = i.get(\"p1_pokemon_state\").get(\"name\")\n                if i.get('p1_move_details').get('category') == 'SPECIAL':\n                    count_p1 += 1\n                    sp_atk_1 += next(p.get('base_spa', 0) for p in p1_team if p.get(\"name\") == nome_p1)\n            if i.get(\"p2_move_details\"):\n                if i.get('p2_move_details').get('category') == 'SPECIAL':\n                    count_p2 += 1\n        \n        features['n_sp_atk_1'] = count_p1\n        features['n_sp_atk_2'] = count_p2\n        \n        \n        # --- Number of times that each player uses blizard / ice beam ---\n        \n        count_move_p1_frz = 0\n        count_move_p2_frz = 0\n\n        count_move_p1_frz = sum(1 for turn in battle_timeline \n                                if turn.get(\"p1_move_details\") \n                                and turn.get(\"p1_move_details\").get(\"name\") in [\"blizzard\", \"icebeam\"])\n            \n        count_move_p2_frz = sum(1 for turn in battle_timeline \n                                if turn.get(\"p2_move_details\") \n                                and turn.get(\"p2_move_details\").get(\"name\") in [\"blizzard\", \"icebeam\"])\n            \n        features[\"move_p1_blz-icb\"] = count_move_p1_frz\n        features[\"move_p2_blz-icb\"] = count_move_p2_frz          \n\n        # --- Number of times that each player uses thunderwave ---\n        \n        count_move_p1_spe = 0\n        count_move_p2_spe = 0\n\n        count_move_p1_spe = sum(1 for turn in battle_timeline\n                                if turn.get(\"p1_move_details\") \n                                and turn.get(\"p1_move_details\").get(\"name\") == \"thunderwave\")\n            \n        count_move_p2_spe = sum(1 for turn in battle_timeline\n                                if turn.get(\"p2_move_details\") \n                                and turn.get(\"p2_move_details\").get(\"name\") == \"thunderwave\")\n            \n        features[\"move_p1_tw\"] = count_move_p1_spe\n        features[\"move_p2_tw\"] = count_move_p1_spe\n\n        # --- Interactions ---\n\n        features[\"p2_status x null_p2\"] = features[\"p2_status\"]*null_2\n        features[\"p1_status x null_p1\"] = features[\"p1_status\"]*null_1\n\n         \n        # --- ID and the target variable ---\n        features['battle_id'] = battle.get('battle_id')\n        if 'player_won' in battle:\n            features['player_won'] = int(battle['player_won'])\n            \n        feature_list.append(features)\n        \n    return pd.DataFrame(feature_list).fillna(0)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:56:37.244387Z","iopub.execute_input":"2025-11-13T20:56:37.244623Z","iopub.status.idle":"2025-11-13T20:56:37.372081Z","shell.execute_reply.started":"2025-11-13T20:56:37.244607Z","shell.execute_reply":"2025-11-13T20:56:37.371552Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We call the function twice, first giving as input the train data and then the test data such that we obtain the two dataframe for training and test. Then we create the final datasets for training (removing ID's & target features) and for the test.","metadata":{}},{"cell_type":"code","source":"# Features' dataframe for training set\n\ntrain_df = create_simple_features(train_data)\n\n# Features' dataframe for training set\n\ntest_df = create_simple_features(test_data)\n\ndisplay(train_df.head(5))\ndisplay(train_df.tail(5))\n\ntrain_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:56:43.411945Z","iopub.execute_input":"2025-11-13T20:56:43.412199Z","iopub.status.idle":"2025-11-13T20:56:46.772788Z","shell.execute_reply.started":"2025-11-13T20:56:43.412181Z","shell.execute_reply":"2025-11-13T20:56:46.772226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Defining our features (X) and target (y)\n\nfeatures = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\n\nX_train = train_df[features]\ny_train = train_df['player_won']\n\nX_test = test_df[features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:57:30.123432Z","iopub.execute_input":"2025-11-13T20:57:30.123660Z","iopub.status.idle":"2025-11-13T20:57:30.129750Z","shell.execute_reply.started":"2025-11-13T20:57:30.123646Z","shell.execute_reply":"2025-11-13T20:57:30.129223Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Scaling**  \nDue to the fact that having features on different scales can create problems and confusion in some models (e.g. knn) we rescale all the variable to mean = 0 and standard deviation = 1.","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)\n\nX_train_scaled_df = pd.DataFrame(X_train_scaled, columns= features )\nX_train_scaled_df.head()\nX_train_scaled_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:57:32.888823Z","iopub.execute_input":"2025-11-13T20:57:32.889080Z","iopub.status.idle":"2025-11-13T20:57:33.425853Z","shell.execute_reply.started":"2025-11-13T20:57:32.889062Z","shell.execute_reply":"2025-11-13T20:57:33.425158Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Building the model**","metadata":{}},{"cell_type":"markdown","source":"**Grid Search**  \nImplementation of grid search in order to find the best hyperparameters for the logistic regression.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\n\nmodel = LogisticRegression(random_state=42, max_iter=1000)\n\n\nparam_grid = {\n    'C': [0.1, 0.5, 1, 1.5, 2],\n    'penalty': ['l1', 'l2'],\n    'solver': ['liblinear', 'lbfgs']\n}\n\n\ngrid_logreg = GridSearchCV(\n    estimator=model,\n    param_grid=param_grid,\n    scoring=['roc_auc', 'accuracy'],\n    n_jobs=4,        \n    cv=5,            \n    refit='roc_auc',  #  the metric by which we want to take the best estimator     \n    return_train_score=True\n)\n\n\ngrid_logreg.fit(X_train_scaled, y_train)\n\ncv_results_df = pd.DataFrame(grid_logreg.cv_results_)\n\npredictions_lr = grid_logreg.best_estimator_.predict(X_test_scaled)\n\nprint(\"Predicted labels:\", predictions_lr[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:59:12.273531Z","iopub.execute_input":"2025-11-13T20:59:12.273774Z","iopub.status.idle":"2025-11-13T20:59:13.863964Z","shell.execute_reply.started":"2025-11-13T20:59:12.273758Z","shell.execute_reply":"2025-11-13T20:59:13.863229Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Displayining of the results obtained:\n- best score (w.r.t. the metric we used so AUC)\n- value of accuracy of the model\n- value of the hyperparameters\n- coefficients of the model","metadata":{}},{"cell_type":"code","source":"best_score = grid_logreg.best_score_\nprint(\"Best ROC_AUC score:\", best_score) # output: the biggest AUC w.r.t. mean_test_score \n\n\ncv_df = pd.DataFrame(grid_logreg.cv_results_)\nbest_idx = grid_logreg.best_index_\nmean_acc = cv_df.loc[best_idx, 'mean_test_accuracy']\nprint(\"\\naccuracy\",mean_acc) \n\n\nbest_params = grid_logreg.best_params_\nprint(\"\\nBest hyperparameters:\\n\",best_params) # ouput: hyperparameters used in the best model\n\nbest_log_reg = grid_logreg.best_estimator_\n\n\n# model's coefficients\n\ncoef = best_log_reg.coef_.flatten()\n\nfeature_names = X_train.columns\n\ncoef_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Coefficient': abs(coef)\n}).sort_values(by='Coefficient', ascending=False)\n\nprint(coef_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:59:30.382734Z","iopub.execute_input":"2025-11-13T20:59:30.382976Z","iopub.status.idle":"2025-11-13T20:59:30.392022Z","shell.execute_reply.started":"2025-11-13T20:59:30.382960Z","shell.execute_reply":"2025-11-13T20:59:30.391447Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**KNN**  \nImplementation of KNN and of its elbow plot in order to find the best k.","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nks = range(1, 30)\n\nscores = [\n    cross_val_score(KNeighborsClassifier(n_neighbors=k), X_train_scaled, y_train, cv=5).mean()\n    for k in ks\n]\n\nplt.plot(ks, scores, marker='o')\nplt.xlabel('k (number of neighbors)')\nplt.ylabel('Cross-Validation Accuracy')\nplt.title('Choosing the Optimal k in KNN')\nplt.grid(True)\nplt.show()\n\n# elbow at k = 18","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T20:59:47.902978Z","iopub.execute_input":"2025-11-13T20:59:47.903201Z","iopub.status.idle":"2025-11-13T21:00:02.882610Z","shell.execute_reply.started":"2025-11-13T20:59:47.903186Z","shell.execute_reply":"2025-11-13T21:00:02.882051Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Computing accuracy of KNN on training set with cross-validation","metadata":{}},{"cell_type":"code","source":"acc_knn = cross_val_score(KNeighborsClassifier(n_neighbors = 18), X_train_scaled, y_train, cv = 5).mean()\nprint(acc_knn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:01:51.985475Z","iopub.execute_input":"2025-11-13T21:01:51.985684Z","iopub.status.idle":"2025-11-13T21:01:52.471675Z","shell.execute_reply.started":"2025-11-13T21:01:51.985671Z","shell.execute_reply":"2025-11-13T21:01:52.470978Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**XGboost**","metadata":{}},{"cell_type":"code","source":"pip install xgboost -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T14:22:08.483800Z","iopub.execute_input":"2025-11-09T14:22:08.484160Z","iopub.status.idle":"2025-11-09T14:22:14.269241Z","shell.execute_reply.started":"2025-11-09T14:22:08.484136Z","shell.execute_reply":"2025-11-09T14:22:14.268048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nacc_xgb = cross_val_score(xgb_clf, X_train_scaled, y_train, cv =5).mean()\nprint(acc_xgb )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:04:53.445692Z","iopub.execute_input":"2025-11-13T21:04:53.445938Z","iopub.status.idle":"2025-11-13T21:05:00.830030Z","shell.execute_reply.started":"2025-11-13T21:04:53.445921Z","shell.execute_reply":"2025-11-13T21:05:00.829091Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Random forest**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\nacc_rf = cross_val_score(rf_clf, X_train_scaled, y_train, cv = 5).mean()\n\nprint(acc_rf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:05:12.675103Z","iopub.execute_input":"2025-11-13T21:05:12.675865Z","iopub.status.idle":"2025-11-13T21:06:01.895433Z","shell.execute_reply.started":"2025-11-13T21:05:12.675838Z","shell.execute_reply":"2025-11-13T21:06:01.894785Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Ensamble (Voting)**  \nOur choice for this submission is to use voting ensamble technique using as models all the ones computed previously:\n- logistic regression\n- knn\n- xgboost\n- random forest\\\nThe idea is to label every observation according to the mean of the probabilities given by the 4 models. In order to have a more reliable estimate we computed a cross validation on the final model","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nlog_clf = best_log_reg\nknn_clf = KNeighborsClassifier(n_neighbors = 18)\n\n\n# voting with logistic regression, knn, xgboost and random forest\n\nvoting_xgb_rf = VotingClassifier(\n    estimators=[\n        ('lr', log_clf),\n        ('xgb', xgb_clf),\n        ('knn', knn_clf),\n        ('rf', rf_clf)\n    ],\n    voting='soft'  # --> average predicted probabilities\n)\nvoting_acc_xgb_rf = cross_val_score(voting_xgb_rf, X_train_scaled, y_train, cv = 5).mean()\nvoting_xgb_rf.fit(X_train, y_train)\npredictions_vot_xgb_rf = voting_xgb_rf.predict(X_test)\n\n\nprint(f\"accuracy con xgboost e rf {voting_acc_xgb_rf}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T21:12:23.082446Z","iopub.execute_input":"2025-11-13T21:12:23.082685Z","iopub.status.idle":"2025-11-13T21:12:36.570734Z","shell.execute_reply.started":"2025-11-13T21:12:23.082669Z","shell.execute_reply":"2025-11-13T21:12:36.570090Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Creating the Submission File**\n\nThe competition requires a `.csv` file with two columns: `battle_id` and `player_won`. Let's use our trained model to make predictions on the test set and format them correctly.","metadata":{}},{"cell_type":"code","source":"# Make predictions on the test data\nprint(\"Generating predictions on the test set...\")\n#test_predictions = model.predict(X_test)\n\n# Create the submission DataFrame\nsubmission_df = pd.DataFrame({\n    'battle_id': test_df['battle_id'],\n    #'player_won': test_predictions\n    'player_won': predictions_vot_xgb_rf\n})\n\n# Save the DataFrame to a .csv file\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"\\n'submission.csv' file created successfully!\")\ndisplay(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T14:24:40.216714Z","iopub.execute_input":"2025-11-09T14:24:40.217108Z","iopub.status.idle":"2025-11-09T14:24:40.245458Z","shell.execute_reply.started":"2025-11-09T14:24:40.217076Z","shell.execute_reply":"2025-11-09T14:24:40.244452Z"}},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":107555,"databundleVersionId":13033998,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Submission with voting with rf and xgboost","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nimport os\nimport numpy as np\n\n# --- Define the path to our data ---\nCOMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\nDATA_PATH = os.path.join('../input', COMPETITION_NAME)\n\ntrain_file_path = os.path.join(DATA_PATH, 'train.jsonl')\ntest_file_path = os.path.join(DATA_PATH, 'test.jsonl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:15:52.292423Z","iopub.execute_input":"2025-11-12T08:15:52.292679Z","iopub.status.idle":"2025-11-12T08:15:52.680705Z","shell.execute_reply.started":"2025-11-12T08:15:52.292660Z","shell.execute_reply":"2025-11-12T08:15:52.679808Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = []\n\n# Read the file line by line\nprint(f\"Loading data from '{train_file_path}'...\")\ntry:\n    with open(train_file_path, 'r') as f:\n        for line in f:\n            # json.loads() parses one line (one JSON object) into a Python dictionary\n            train_data.append(json.loads(line))\n        print(f\"Successfully loaded {len(train_data)} battles.\")\n    # Let's inspect the first battle to see its structure\n    print(\"\\n--- Structure of the first train battle: ---\")\n    if train_data:\n        first_battle = train_data[7]\n        \n        # To keep the output clean, we can create a copy and truncate the timeline\n        battle_for_display = first_battle.copy()\n        battle_for_display['battle_timeline'] = battle_for_display.get('battle_timeline', [])#[:2] # Show first 2 turns\n        \n        # Use json.dumps for pretty-printing the dictionary\n        print(json.dumps(battle_for_display, indent=4))\n        if len(first_battle.get('battle_timeline', [])) > 3:\n            print(\"    ...\")\n            print(\"    (battle_timeline has been truncated for display)\")\n\n\nexcept FileNotFoundError:\n    print(f\"ERROR: Could not find the training file at '{train_file_path}'.\")\n    print(\"Please make sure you have added the competition data to this notebook.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:43:21.013938Z","iopub.execute_input":"2025-11-12T08:43:21.014994Z","iopub.status.idle":"2025-11-12T08:43:29.784854Z","shell.execute_reply.started":"2025-11-12T08:43:21.014872Z","shell.execute_reply":"2025-11-12T08:43:29.783923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = []\n\nprint(f\"Loading data from '{test_file_path}'...\")\ntry:\n    with open(test_file_path, 'r') as f:\n        for line in f:\n            test_data.append(json.loads(line))\n    \n    print(\"\\n--- Structure of the first test battle: ---\")\n    if test_data:\n            first_test_battle = test_data[0]\n            \n            # To keep the output clean, we can create a copy and truncate the timeline\n            test_battle_for_display = first_test_battle.copy()\n            test_battle_for_display['battle_timeline'] = test_battle_for_display.get('battle_timeline', [])[:5] # Show first 2 turns\n            \n            # Use json.dumps for pretty-printing the dictionary\n            print(json.dumps(test_battle_for_display, indent=4))\n            if len(first_test_battle.get('battle_timeline', [])) > 3:\n                print(\"    ...\")\n                print(\"    (battle_timeline has been truncated for display)\")\n\n\nexcept FileNotFoundError:\n    print(f\"ERROR: Could not find the training file at '{test_file_path}'.\")\n    print(\"Please make sure you have added the competition data to this notebook.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:16:12.341746Z","iopub.execute_input":"2025-11-12T08:16:12.342025Z","iopub.status.idle":"2025-11-12T08:16:15.379495Z","shell.execute_reply.started":"2025-11-12T08:16:12.342003Z","shell.execute_reply":"2025-11-12T08:16:15.378621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Codice per creare nuove variabili:\n- Percentuale di turni in cui il pokemon del player presenta uno status (1 per giocatore)\n- Numero totale di boosts ricevuti (1 per ogni giocatore)\n- Numero di turni \"null\" (1 per giocatore)\n- Media accuracy (1 per giocatore)\n- Numero di volte in cui un giocatore attacca (1 per giocatore)\n- Somma della priority (1 per giocatore)","metadata":{}},{"cell_type":"code","source":"\ntypes = [\n    \"bug\", \"dark\", \"dragon\", \"electric\", \"fairy\", \"fighting\", \"fire\", \"flying\",\n    \"ghost\", \"grass\", \"ground\", \"ice\", \"normal\", \"poison\", \"psychic\", \"rock\",\n    \"steel\", \"stellar\", \"water\"\n]\n\n# Matrice delle efficacie (valori numerici)\n# x2 = 2.0, xÂ½ = 0.5, x0 = 0.0, x1 = 1.0\n# Ogni riga corrisponde al tipo attaccante, ogni colonna al tipo difensore\ntype_chart = np.array([\n#  Bu  Da  Dr  El  Fa  Fi  Fi  Fl  Gh  Gr  Gr  Ic  No  Po  Ps  Ro  St  St  Wa\n  [1,  2,  1,  1,  1,  0.5,0.5,0.5,1,  2,  1,  1,  1,  0.5,2,  1,  0.5,1,  1],  # Bug\n  [1,  0.5,1,  1,  2,  1,  1,  1,  2,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1],  # Dark\n  [1,  1,  2,  1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0.5,1,  1],  # Dragon\n  [1,  1,  0.5,0.5,1,  1,  1,  2,  1,  0.5,0,  1,  1,  1,  1,  1,  1,  1,  2],  # Electric\n  [1,  2,  2,  1,  1,  0.5,0.5,1,  1,  1,  1,  1,  1,  0.5,1,  1,  0.5,1,  1],  # Fairy\n  [0.5,2,  1,  1,  0.5,1,  1,  0,  1,  1,  1,  2,  1,  0.5,2,  2,  1,  1,  1],  # Fighting\n  [0.5,1,  0.5,1,  1,  1,  0.5,1,  1,  2,  1,  2,  1,  1,  1,  0.5,0.5,1,  0.5],# Fire\n  [2,  1,  1,  0.5,1,  2,  1,  1,  1,  2,  1,  1,  1,  1,  1,  0.5,0.5,1,  1],  # Flying\n  [1,  0.5,1,  1,  1,  1,  1,  1,  2,  1,  1,  1,  0,  1,  2,  1,  1,  1,  1],  # Ghost\n  [0.5,1,  1,  1,  1,  1,  0.5,0.5,1,  0.5,2,  1,  1,  0.5,1,  2,  0.5,1,  0.5],# Grass\n  [0.5,1,  1,  2,  1,  1,  2,  0,  1,  0.5,1,  2,  1,  2,  1,  2,  1,  1,  1],  # Ground\n  [1,  1,  2,  1,  1,  1,  0.5,2,  1,  2,  1,  0.5,1,  1,  1,  1,  0.5,1,  0.5],# Ice\n  [1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  0.5,0.5,1,  1],  # Normal\n  [1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  0.5, 1,  1,  0.5,1,  0.5,0,  1,  1], # Poison\n  [1,  2,  1,  1,  1,  0.5,1,  1,  1,  1,  1,  1,  1,  1,  0.5, 1,  0.5,1,  1], # Psychic\n  [2,  1,  1,  1,  1,  0.5,2,  2,  1,  1,  0.5, 2,  1,  1,  1,  1,  0.5,1,  1], # Rock\n  [1,  1,  0.5,0.5,1,  1,  2,  1,  1,  1,  2,  2,  1,  1,  1,  2,  0.5,1,  0.5],# Steel\n  [1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],  # Stellar\n  [1,  1,  1,  1,  1,  1,  2,  1,  1,  2,  1,  0.5,1,  1,  1,  2,  1,  1,  0.5] # Water\n])\n\n# Converti in DataFrame per etichette leggibili\ntype_chart_df = pd.DataFrame(type_chart, index=types, columns=types)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:16:22.694859Z","iopub.execute_input":"2025-11-12T08:16:22.695137Z","iopub.status.idle":"2025-11-12T08:16:22.709018Z","shell.execute_reply.started":"2025-11-12T08:16:22.695118Z","shell.execute_reply":"2025-11-12T08:16:22.708015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"count_level = 0\npokemon_not_level_100 = []\nfor battle in train_data:\n    squad = battle.get(\"p1_team_details\")\n    for pokemon in squad:\n        level = pokemon.get(\"level\")\n        if level != 100:\n            print(pokemon.get(\"name\"), pokemon.get(\"level\"))\n            count_level += 1\n            pokemon_not_level_100.append(pokemon)\n#print(count_level)\n#print(pokemon_not_level_100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T14:12:53.978332Z","iopub.execute_input":"2025-11-09T14:12:53.978741Z","iopub.status.idle":"2025-11-09T14:12:54.046152Z","shell.execute_reply.started":"2025-11-09T14:12:53.978711Z","shell.execute_reply":"2025-11-09T14:12:54.045070Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"used_pokemon = set()\ncount = 0\nfor battle in train_data:\n    battle_timeline = battle.get('battle_timeline', [])\n    for i in battle_timeline:\n        nome_p1 = i.get(\"p1_pokemon_state\").get(\"name\")\n        nome_p2 = i.get(\"p2_pokemon_state\").get(\"name\")\n        if nome_p1 not in used_pokemon:\n            used_pokemon.add(nome_p1)\n            count += 1\n        if nome_p2 not in used_pokemon:\n            used_pokemon.add(nome_p2)\n            count += 1\nprint(count)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T14:12:54.047291Z","iopub.execute_input":"2025-11-09T14:12:54.047572Z","iopub.status.idle":"2025-11-09T14:12:54.342790Z","shell.execute_reply.started":"2025-11-09T14:12:54.047548Z","shell.execute_reply":"2025-11-09T14:12:54.341671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pokedex = {}\n\nfor battle in train_data:\n    squad = battle.get(\"p1_team_details\")\n    for pokemon in squad:\n        nome = pokemon.get(\"name\")\n        if nome not in pokedex:\n            pokedex[nome] = pokemon\n    pokemon_p2 = battle.get(\"p2_lead_details\").get(\"name\")\n    if pokemon_p2 not in pokedex:\n        pokedex[pokemon_p2] = battle.get(\"p2_lead_details\")\n\nprint(len(pokedex))\nprint(json.dumps(pokedex, indent=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T08:16:32.179106Z","iopub.execute_input":"2025-11-12T08:16:32.179412Z","iopub.status.idle":"2025-11-12T08:16:32.240068Z","shell.execute_reply.started":"2025-11-12T08:16:32.179390Z","shell.execute_reply":"2025-11-12T08:16:32.238900Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport numpy as np\n\ndef create_simple_features(data: list[dict]) -> pd.DataFrame:\n    \"\"\"\n    A very basic feature extraction function.\n    It only uses the aggregated base stats of the player's team and opponent's lead.\n    \"\"\"\n    feature_list = []\n    for battle in tqdm(data, desc=\"Extracting features\"):\n        features = {}\n        \n        # --- Player 1 Team Features ---\n        \n        p1_team = battle.get('p1_team_details', [])\n        if p1_team:\n            features['p1_mean_hp'] = np.mean([p.get('base_hp', 0) for p in p1_team])\n            features['p1_mean_spe'] = np.mean([p.get('base_spe', 0) for p in p1_team])\n            features['p1_mean_atk'] = np.mean([p.get('base_atk', 0) for p in p1_team])\n            features['p1_mean_def'] = np.mean([p.get('base_def', 0) for p in p1_team])\n            features['p1_mean_spa'] = np.mean([p.get('base_spa', 0) for p in p1_team])\n            features['p1_mean_spd'] = np.mean([p.get('base_spd', 0) for p in p1_team])\n\n        # --- Player 2 Partial Team Features ---\n\n        battle_timeline = battle.get('battle_timeline', [])\n        p2_team = {}\n        for i in battle_timeline:\n            name_p2 = i.get(\"p2_pokemon_state\", {}).get(\"name\")\n            if name_p2:\n                p2_team[name_p2] = pokedex.get(name_p2, {})\n        features['p2_mean_hp'] = np.mean([p2_team[p].get('base_hp', 0) for p in p2_team])\n        features['p2_mean_spe'] = np.mean([p2_team[p].get('base_spe', 0) for p in p2_team])\n        features['p2_mean_atk'] = np.mean([p2_team[p].get('base_atk', 0) for p in p2_team])\n        features['p2_mean_def'] = np.mean([p2_team[p].get('base_def', 0) for p in p2_team])\n        features['p2_mean_spa'] = np.mean([p2_team[p].get('base_spa', 0) for p in p2_team])\n        features['p2_mean_spd'] = np.mean([p2_team[p].get('base_spd', 0) for p in p2_team])\n\n        # --- Players Status pokemon ---\n        \n        status_p1 = (sum(i.get(\"p1_pokemon_state\", {}).get(\"status\") != \"nostatus\" for i in battle_timeline))/len(battle_timeline)\n        status_p2 = (sum(i.get(\"p2_pokemon_state\", {}).get(\"status\") != \"nostatus\" for i in battle_timeline))/len(battle_timeline)\n\n        features['p1_status'] =  round(status_p1,3)\n        features['p2_status'] =  round(status_p2,3)\n\n        # --- Players Boosts ---\n                \n        boosts_p1 = sum(sum(i.get(\"p1_pokemon_state\", {}).get(\"boosts\", {}).values()) for i in battle_timeline)\n        boosts_p2 = sum(sum(i.get(\"p2_pokemon_state\", {}).get(\"boosts\", {}).values()) for i in battle_timeline)\n        \n        features[\"diff_boost\"] = boosts_p1 - boosts_p2\n        \n        # --- Players' move \"null\" ---\n        \n        null_1 = sum(not i.get(\"p1_move_details\") for i in battle_timeline)\n        null_2 = sum(not i.get(\"p2_move_details\") for i in battle_timeline)\n        \n        features['null_p1'] = null_1\n        features['null_p2'] = null_2\n\n        # --- Players' accuracy ---\n        \n        acc_1_list = [float(i[\"p1_move_details\"][\"accuracy\"]) for i in battle_timeline if i.get(\"p1_move_details\")]\n\n        acc_2_list = [float(i[\"p2_move_details\"][\"accuracy\"]) for i in battle_timeline if i.get(\"p2_move_details\")]\n\n        avg_acc1 = sum(acc_1_list) / len(acc_1_list) if acc_1_list else 0\n        avg_acc2 = sum(acc_2_list) / len(acc_2_list) if acc_2_list else 0\n\n        features[\"diff_avg_acc\"] = avg_acc1 - avg_acc2\n\n        \n        # Number of times that each player attacks\n\n        diz_p1 = {}\n        count_p2 = 0\n        for i in battle_timeline:\n            nome = i.get('p1_pokemon_state').get('name')\n            hp = i.get('p1_pokemon_state').get('hp_pct')\n            if nome not in diz_p1:\n                if int(hp) != 1:\n                    diz_p1[nome] = hp\n                    count_p2 += 1\n                else:\n                    diz_p1[nome] = hp\n            else:\n                if diz_p1[nome] > hp:\n                    diz_p1[nome] = hp\n                    count_p2 += 1\n                else:\n                    diz_p1[nome] = hp\n        diz_p2 = {}\n        count_p1 = 0\n        for i in battle_timeline:\n            nome = i.get('p2_pokemon_state').get('name')\n            hp = i.get('p2_pokemon_state').get('hp_pct')\n            if nome not in diz_p2:\n                if int(hp) != 1:\n                    diz_p2[nome] = hp\n                    count_p1 += 1\n                else:\n                    diz_p2[nome] = hp\n            else:\n                if diz_p2[nome] > hp:\n                    diz_p2[nome] = hp\n                    count_p1 += 1\n                else:\n                    diz_p2[nome] = hp\n\n        features['n_atk_p1'] = count_p1\n        features['n_atk_p2'] = count_p2\n\n        \n        # Diff damage inflicted\n\n        diz_1 = {}\n        def_p1 = 0\n        diz_2 = {}\n        atk_p1 = 0\n        for i in battle_timeline:\n            # sum of p1 defense\n            diff_p1 = 0\n            nome_1 = i.get(\"p1_pokemon_state\").get(\"name\")\n            hp_1 = i.get(\"p1_pokemon_state\").get(\"hp_pct\")\n            if nome_1 not in diz_1:\n                if int(hp_1) != 1:\n                    diff_p1 = 1 - hp_1\n                    diz_1[nome_1] = hp_1\n                else:\n                    diz_1[nome_1] = hp_1\n            else:\n                diff_p1 = diz_1[nome_1] - hp_1\n                diz_1[nome_1] = hp_1\n            def_p1 += diff_p1 \n            \n        for i in battle_timeline:\n            # sum of p1 attack\n            diff_p2 = 0\n            nome_2 = i.get(\"p2_pokemon_state\").get(\"name\")\n            hp_2 = i.get(\"p2_pokemon_state\").get(\"hp_pct\")   \n            if nome_2 not in diz_2:\n                if int(hp_2) != 1:\n                    diff_p2 = 1 - hp_2\n                    diz_2[nome_2] = hp_2\n                else:\n                    diz_2[nome_2] = hp_2\n            else:\n                diff_p2 = diz_2[nome_2] - hp_2\n                diz_2[nome_2] = hp_2\n            atk_p1 += diff_p2\n        \n        features[\"diff_damage\"] = atk_p1 - def_p1\n        \n        \n        # Count priority\n        \n        priority_1 = sum(i[\"p1_move_details\"][\"priority\"] for i in battle_timeline if i.get(\"p1_move_details\"))\n        priority_2 = sum(i[\"p2_move_details\"][\"priority\"] for i in battle_timelinecif i.get(\"p2_move_details\"))\n        \n        features[\"priority_1\"] = priority_1\n        features[\"priority_2\"] = priority_2\n\n        \n        # --- Players' KO ---\n\n        count_p1 = sum(i.get('p1_pokemon_state', {}).get('status') == 'fnt' for i in battle_timeline)\n        count_p2 = sum(i.get('p2_pokemon_state', {}).get('status') == 'fnt' for i in battle_timeline)\n        \n        features['ko_p1'] = count_p1\n        features['ko_p2'] = count_p2\n\n\n        # --- Number of special attacks ---\n        \n        count_p1 = 0\n        sp_atk_1 = 0\n        count_p2 = 0\n        sp_def_1 = 0\n        for i in battle_timeline:\n            if i.get(\"p1_move_details\"):\n                nome_p1 = i.get(\"p1_pokemon_state\").get(\"name\")\n                if i.get('p1_move_details').get('category') == 'SPECIAL':\n                    count_p1 += 1\n                    sp_atk_1 += next(p.get('base_spa', 0) for p in p1_team if p.get(\"name\") == nome_p1)\n            if i.get(\"p2_move_details\"):\n                if i.get('p2_move_details').get('category') == 'SPECIAL':\n                    count_p2 += 1\n        features['n_sp_atk_1'] = count_p1\n        features['n_sp_atk_2'] = count_p2\n        \n        \n        # Number of times that each player uses blizard / ice beam\n        \n        count_move_p1_frz = 0\n        count_move_p2_frz = 0\n\n        for i in battle_timeline:\n            if i.get(\"p1_move_details\"):\n                move = i.get(\"p1_move_details\").get(\"name\")\n                if move == \"blizzard\" or move == \"icebeam\":\n                    count_move_p1_frz += 1\n            \n            if i.get(\"p2_move_details\"):\n                move = i.get(\"p2_move_details\").get(\"name\")\n                if move == \"blizzard\" or move == \"icebeam\":\n                    count_move_p2_frz += 1\n                    \n\n        # Number of times that each player uses thunderwave\n        \n        count_move_p1_spe = 0\n        count_move_p2_spe = 0\n\n        for i in battle_timeline:\n            if i.get(\"p1_move_details\"):\n                move = i.get(\"p1_move_details\").get(\"name\")\n                if move == \"thunderwave\":\n                    count_move_p1_spe += 1\n            \n            if i.get(\"p2_move_details\"):\n                move = i.get(\"p2_move_details\").get(\"name\")\n                if move == \"thunderwave\":\n                    count_move_p2_spe += 1\n\n        features[\"move_p1_blic\"] = count_move_p1_frz\n        features[\"move_p2_blic\"] = count_move_p2_frz\n        features[\"move_p1_tw\"] = count_move_p1_spe\n        features[\"move_p2_tw\"] = count_move_p1_spe\n\n        features[\"p2_status x null_p2\"] = features[\"p2_status\"]*null_2\n        features[\"p1_status x null_p1\"] = features[\"p1_status\"]*null_1\n\n         \n        # We also need the ID and the target variable (if it exists)\n        features['battle_id'] = battle.get('battle_id')\n        if 'player_won' in battle:\n            features['player_won'] = int(battle['player_won'])\n            \n        feature_list.append(features)\n        \n    return pd.DataFrame(feature_list).fillna(0)\n\n# Create feature DataFrames for both training and test sets\n#print(\"Processing training data...\")\ntrain_df = create_simple_features(train_data)\n\n#print(\"\\nProcessing test data...\")\n\ntest_df = create_simple_features(test_data)\n\n#print(\"\\nTraining features preview:\")\ndisplay(train_df.head(5))\ndisplay(train_df.tail(5))\n\ntrain_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:35:47.918383Z","iopub.execute_input":"2025-11-12T11:35:47.918705Z","iopub.status.idle":"2025-11-12T11:35:54.917408Z","shell.execute_reply.started":"2025-11-12T11:35:47.918682Z","shell.execute_reply":"2025-11-12T11:35:54.916550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Define our features (X) and target (y)\nfeatures = [col for col in train_df.columns if col not in ['battle_id', 'player_won']]\nX_train = train_df[features]\ny_train = train_df['player_won']\n\nX_test = test_df[features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:35:58.566888Z","iopub.execute_input":"2025-11-12T11:35:58.567637Z","iopub.status.idle":"2025-11-12T11:35:58.575106Z","shell.execute_reply.started":"2025-11-12T11:35:58.567608Z","shell.execute_reply":"2025-11-12T11:35:58.574221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Scaling**","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)\n\nX_train_scaled_df = pd.DataFrame(X_train_scaled, columns= features )\nX_train_scaled_df.head()\nX_train_scaled_df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:36:01.466457Z","iopub.execute_input":"2025-11-12T11:36:01.466756Z","iopub.status.idle":"2025-11-12T11:36:01.566055Z","shell.execute_reply.started":"2025-11-12T11:36:01.466734Z","shell.execute_reply":"2025-11-12T11:36:01.565123Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Grid Search**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\n\nmodel = LogisticRegression(random_state=42, max_iter=1000)\n\n# Define the parameter grid to search\nparam_grid = {\n    'C': [0.1, 0.5, 1, 1.5, 2],\n    'penalty': ['l1', 'l2'],\n    'solver': ['liblinear', 'lbfgs']\n}\n\n# Create the GridSearchCV object\ngrid_logreg = GridSearchCV(\n    estimator=model,\n    param_grid=param_grid,\n    scoring=['roc_auc', 'accuracy'],\n    n_jobs=4,        # use 4 cores in parallel\n    cv=5,            # 5-fold cross-validation, more on this later\n    refit='roc_auc',      # retrain the best model on the full training set\n    return_train_score=True\n)\n\n# Fit the GridSearchCV object on the training data\ngrid_logreg.fit(X_train_scaled, y_train)\n\n# Read the cv_results_ property into a DataFrame\ncv_results_df = pd.DataFrame(grid_logreg.cv_results_)\n\n# Check what type of object the best_estimator_ property returns\nprint(type(grid_logreg.best_estimator_))\n\n# Use the best estimator to make predictions on the test set\npredictions_lr = grid_logreg.best_estimator_.predict(X_test_scaled)\n\n# Display a few predicted class labels (0 = benign, 1 = malignant)\nprint(\"Predicted labels:\", predictions_lr[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:36:04.510636Z","iopub.execute_input":"2025-11-12T11:36:04.511452Z","iopub.status.idle":"2025-11-12T11:36:06.789989Z","shell.execute_reply.started":"2025-11-12T11:36:04.511422Z","shell.execute_reply":"2025-11-12T11:36:06.789147Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_score = grid_logreg.best_score_\nprint(\"Best ROC_AUC score:\", best_score) # output: the biggest AUC w.r.t. mean_test_score \n\n\ncv_df = pd.DataFrame(grid_logreg.cv_results_)\nbest_idx = grid_logreg.best_index_\nmean_acc = cv_df.loc[best_idx, 'mean_test_accuracy']\nprint(\"\\naccuracy\",mean_acc) \n\nmean_auc = cv_df.loc[best_idx, 'mean_test_roc_auc']\nprint(\"\\nauc\",mean_auc) \n\nbest_params = grid_logreg.best_params_\nprint(\"\\nBest hyperparameters:\\n\",best_params) # ouput: hyperparameters used in the best model\n\n# Estrai il modello migliore\nbest_log_reg = grid_logreg.best_estimator_\n\n# Coefficienti del modello (per una regressione logistica)\n\ncoef = best_log_reg.coef_.flatten()\n\nfeature_names = X_train.columns\n\ncoef_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Coefficient': abs(coef)\n}).sort_values(by='Coefficient', ascending=False)\n\nprint(coef_df)\n\n# auc = 0.901\n# acc = 0.8301\n# {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:36:10.450958Z","iopub.execute_input":"2025-11-12T11:36:10.451288Z","iopub.status.idle":"2025-11-12T11:36:10.463705Z","shell.execute_reply.started":"2025-11-12T11:36:10.451245Z","shell.execute_reply":"2025-11-12T11:36:10.462797Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**KNN**","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nks = range(1, 30)\n# Compute 5-fold cross-validation accuracy for each k\nscores = [\n    cross_val_score(KNeighborsClassifier(n_neighbors=k), X_train_scaled, y_train, cv=5).mean()\n    for k in ks\n]\nplt.plot(ks, scores, marker='o')\nplt.xlabel('k (number of neighbors)')\nplt.ylabel('Cross-Validation Accuracy')\nplt.title('Choosing the Optimal k in KNN')\nplt.grid(True)\nplt.show()\n\n#elbow at k = 18","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:36:59.065047Z","iopub.execute_input":"2025-11-12T11:36:59.065401Z","iopub.status.idle":"2025-11-12T11:37:19.336110Z","shell.execute_reply.started":"2025-11-12T11:36:59.065377Z","shell.execute_reply":"2025-11-12T11:37:19.335109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc_knn = cross_val_score(KNeighborsClassifier(n_neighbors = 18), X_train_scaled, y_train, cv = 5).mean()\nprint(acc_knn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:37:32.376235Z","iopub.execute_input":"2025-11-12T11:37:32.376567Z","iopub.status.idle":"2025-11-12T11:37:33.094963Z","shell.execute_reply.started":"2025-11-12T11:37:32.376544Z","shell.execute_reply":"2025-11-12T11:37:33.094138Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Decision tree**","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier, plot_tree","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:22:57.974925Z","iopub.execute_input":"2025-11-12T11:22:57.975799Z","iopub.status.idle":"2025-11-12T11:22:57.982658Z","shell.execute_reply.started":"2025-11-12T11:22:57.975769Z","shell.execute_reply":"2025-11-12T11:22:57.981483Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**XGboost, ADABoost**","metadata":{}},{"cell_type":"code","source":"pip install xgboost -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T14:22:08.483800Z","iopub.execute_input":"2025-11-09T14:22:08.484160Z","iopub.status.idle":"2025-11-09T14:22:14.269241Z","shell.execute_reply.started":"2025-11-09T14:22:08.484136Z","shell.execute_reply":"2025-11-09T14:22:14.268048Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, AdaBoostClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T10:14:59.770357Z","iopub.execute_input":"2025-11-12T10:14:59.770681Z","iopub.status.idle":"2025-11-12T10:14:59.885247Z","shell.execute_reply.started":"2025-11-12T10:14:59.770659Z","shell.execute_reply":"2025-11-12T10:14:59.884540Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from xgboost import XGBClassifier\n\nada_clf = AdaBoostClassifier(\n    DecisionTreeClassifier(max_depth=1),  # weak learner (stump)\n    n_estimators=100,\n    learning_rate=0.5,\n    random_state=42\n)\nacc_ada = cross_val_score(ada_clf, X_train_scaled, y_train, cv =5).mean()\n\n\nxgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nacc_xgb = cross_val_score(xgb_clf, X_train_scaled, y_train, cv =5).mean()\nprint(acc_ada,\"\\n\", acc_xgb )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:37:58.444161Z","iopub.execute_input":"2025-11-12T11:37:58.444937Z","iopub.status.idle":"2025-11-12T11:38:07.449951Z","shell.execute_reply.started":"2025-11-12T11:37:58.444903Z","shell.execute_reply":"2025-11-12T11:38:07.448526Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Random forest, Bagging**","metadata":{}},{"cell_type":"code","source":"rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\nacc_rf = cross_val_score(rf_clf, X_train_scaled, y_train, cv = 5).mean()\n\nprint(acc_rf)\n\nbag_clf = BaggingClassifier(\n    DecisionTreeClassifier(),\n    n_estimators=100,       # number of trees\n    max_samples=0.8,        # each tree sees 80% of training data\n    bootstrap=True,         # sample with replacement\n    random_state=42\n)\nacc_bag = cross_val_score(bag_clf, X_train_scaled, y_train, cv = 5).mean()\n\nprint(acc_bag)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:38:22.219831Z","iopub.execute_input":"2025-11-12T11:38:22.220142Z","iopub.status.idle":"2025-11-12T11:39:21.983511Z","shell.execute_reply.started":"2025-11-12T11:38:22.220116Z","shell.execute_reply":"2025-11-12T11:39:21.982367Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Ensamble (Voting)**","metadata":{}},{"cell_type":"code","source":"log_clf = best_log_reg\nknn_clf = KNeighborsClassifier(n_neighbors = 18)\n\n# voting with random forest\nvoting_rf = VotingClassifier(\n    estimators=[\n        ('lr', log_clf),\n        ('rf', rf_clf),\n        ('knn', knn_clf)\n    ],\n    voting='soft'  # --> average predicted probabilities\n)\nvoting_acc_rf = cross_val_score(voting_rf, X_train_scaled, y_train, cv = 5).mean()\n\n\n# voting with ada_boost\nvoting_ada = VotingClassifier(\n    estimators=[\n        ('lr', log_clf),\n        ('ada', ada_clf),\n        ('knn', knn_clf)\n    ],\n    voting='soft'  # --> average predicted probabilities\n)\nvoting_acc_ada = cross_val_score(voting_ada, X_train_scaled, y_train, cv = 5).mean()\n\n# voting with xgboost\nvoting_xgb = VotingClassifier(\n    estimators=[\n        ('lr', log_clf),\n        ('xgb', xgb_clf),\n        ('knn', knn_clf)\n    ],\n    voting='soft'  # --> average predicted probabilities\n)\nvoting_acc_xgb = cross_val_score(voting_xgb, X_train_scaled, y_train, cv = 5).mean()\n\n# voting with xgboost and rf\nvoting_xgb_rf = VotingClassifier(\n    estimators=[\n        ('lr', log_clf),\n        ('xgb', xgb_clf),\n        ('knn', knn_clf),\n        ('rf', rf_clf)\n    ],\n    voting='soft'  # --> average predicted probabilities\n)\nvoting_acc_xgb_rf = cross_val_score(voting_xgb_rf, X_train_scaled, y_train, cv = 5).mean()\nvoting_xgb_rf.fit(X_train, y_train)\npredictions_vot_xgb_rf = voting_xgb_rf.predict(X_test)\n\n\nprint(f\"accuracy con random forest {voting_acc_rf}\")\nprint(f\"accuracy con ada_boost {voting_acc_ada}\")\nprint(f\"accuracy con xgboost {voting_acc_xgb}\")\nprint(f\"accuracy con xgboost e rf {voting_acc_xgb_rf}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:39:45.298436Z","iopub.execute_input":"2025-11-12T11:39:45.298754Z","iopub.status.idle":"2025-11-12T11:40:18.808933Z","shell.execute_reply.started":"2025-11-12T11:39:45.298730Z","shell.execute_reply":"2025-11-12T11:40:18.808048Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4. Creating the Submission File\n\nThe competition requires a `.csv` file with two columns: `battle_id` and `player_won`. Let's use our trained model to make predictions on the test set and format them correctly.","metadata":{}},{"cell_type":"code","source":"# Make predictions on the test data\nprint(\"Generating predictions on the test set...\")\n#test_predictions = model.predict(X_test)\n\n# Create the submission DataFrame\nsubmission_df = pd.DataFrame({\n    'battle_id': test_df['battle_id'],\n    #'player_won': test_predictions\n    'player_won': predictions_vot_xgb_rf\n})\n\n# Save the DataFrame to a .csv file\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"\\n'submission.csv' file created successfully!\")\ndisplay(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-09T14:24:40.216714Z","iopub.execute_input":"2025-11-09T14:24:40.217108Z","iopub.status.idle":"2025-11-09T14:24:40.245458Z","shell.execute_reply.started":"2025-11-09T14:24:40.217076Z","shell.execute_reply":"2025-11-09T14:24:40.244452Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5. Submitting Your Results\n\nOnce you have generated your `submission.csv` file, there are two primary ways to submit it to the competition.\n\n---\n\n#### Method A: Submitting Directly from the Notebook\n\nThis is the standard method for code competitions. It ensures that your submission is linked to the code that produced it, which is crucial for reproducibility.\n\n1.  **Save Your Work:** Click the **\"Save Version\"** button in the top-right corner of the notebook editor.\n2.  **Run the Notebook:** In the pop-up window, select **\"Save & Run All (Commit)\"** and then click the **\"Save\"** button. This will run your entire notebook from top to bottom and save the output, including your `submission.csv` file.\n3.  **Go to the Viewer:** Once the save process is complete, navigate to the notebook viewer page. \n4.  **Submit to Competition:** In the viewer, find the **\"Submit to Competition\"** section. This is usually located in the header of the output section or in the vertical \"...\" menu on the right side of the page. Clicking the **Submit** button this will submit your generated `submission.csv` file.\n\nAfter submitting, you will see your score in the **\"Submit to Competition\"** section or in the [Public Leaderboard](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?).\n\n---\n\n#### Method B: Manual Upload\n\nYou can also generate your predictions and submission file using any environment you prefer (this notebook, Google Colab, or your local machine).\n\n1.  **Generate the `submission.csv` file** using your model.\n2.  **Download the file** to your computer.\n3.  **Navigate to the [Leaderboard Page](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?)** and click on the **\"Submit Predictions\"** button.\n4.  **Upload Your File:** Drag and drop or select your `submission.csv` file to upload it.\n\nThis method is quick, but keep in mind that for the final evaluation, you might be required to provide the code that generated your submission.\n\nGood luck!","metadata":{}}]}